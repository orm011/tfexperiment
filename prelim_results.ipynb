{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Result = namedtuple('Result', 'iter loss top1 top5')            \n",
    "Info = namedtuple('Info', 'timestamp training validation')\n",
    "\n",
    "# look for the following kinds of lines in the stdout:\n",
    "# fist skip things until we run into a date like the first line. \n",
    "# returns None if EOF reached\n",
    "('[2016-11-23 20:50:26]:\\n',\n",
    " '-Iter 250, Training Loss= 4.2972, Accuracy Top1 = 0.04, Top5 = 0.13\\n',\n",
    " '-Iter 250, Validation Loss= 4.2765, Accuracy Top1 = 0.03, Top5 = 0.16\\n')\n",
    "def parse_next_record(stream):\n",
    "    template = \"\"\"-Iter (?P<iter>[0-9]*), %s Loss= (?P<loss>[\\.0-9]*), Accuracy Top1 = (?P<top1>[\\.0-9]*), Top5 = (?P<top5>[\\.0-9]*)\\n\"\"\"\n",
    "    tr_regex = template % \"Training\"\n",
    "    val_regex = template % \"Validation\"\n",
    "    ptime_regex = '^\\[(.*)\\]:\\n'\n",
    "    \n",
    "    while True:\n",
    "        ln = stream.readline()\n",
    "        if ln == '':\n",
    "            return None\n",
    "            \n",
    "        ptime = re.search(ptime_regex, ln)\n",
    "        if not ptime:\n",
    "            training = re.search(tr_regex,\n",
    "                                 stream.readline())\n",
    "            assert(not training)\n",
    "            validation = re.search(val_regex, \n",
    "                               stream.readline())\n",
    "            assert(not validation)\n",
    "            print(\"skipping: %s\" % ln, file=sys.stderr)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    dt = datetime.strptime(ptime.group(1), '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    ln = stream.readline()\n",
    "    if ln == '':\n",
    "        return None\n",
    "        \n",
    "    training = re.search(tr_regex, ln)\n",
    "    assert(training)\n",
    "    \n",
    "    ln = stream.readline()\n",
    "    if ln == '':\n",
    "        return None\n",
    "    \n",
    "    validation = re.search(val_regex, ln)\n",
    "    assert(validation)\n",
    "    \n",
    "    return Info(timestamp=dt, training=Result(**training.groupdict()), validation=Result(**validation.groupdict()))\n",
    "\n",
    "def parse_records(filename):\n",
    "    st = open(filename, 'r')\n",
    "    recs = []\n",
    "    while True:\n",
    "        el = parse_next_record(st)\n",
    "        if el == None:\n",
    "            return recs\n",
    "        else:\n",
    "            recs.append(el)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (13, 10)\n",
    "data = parse_records('baseline_numbers.txt')\n",
    "\n",
    "ts = [d.timestamp for d in data]\n",
    "iters = [d.training.iter for d in data]\n",
    "training_losses = [d.training.loss for d in data]\n",
    "validation_losses = [d.validation.loss for d in data]\n",
    "training_top5 = [d.training.top5 for d in data]\n",
    "validation_top5 = [d.validation.top5 for d in data]\n",
    "training_top1 = [d.training.top1 for d in data]\n",
    "validation_top1 = [d.validation.top1 for d in data]\n",
    "timestamps = [(d.timestamp - data[0].timestamp).total_seconds() for d in data]\n",
    "iters = [d.training.iter for d in data]\n",
    "\n",
    "f, (ax0,ax1) = plt.subplots(2, sharex=True)\n",
    "plt.suptitle('baseline plot for TF alex net provided by course staff, trained on full training input (random order)')\n",
    "\n",
    "ax0.plot(iters, training_top1, label='training top1')\n",
    "ax0.plot(iters, validation_top1, label='validation top1')\n",
    "ax0.plot(iters, training_top5, label='training top5')\n",
    "ax0.plot(iters, validation_top5, label='validation top5')\n",
    "ax0.set_ylabel('accuracy rate (%)')\n",
    "ax0.legend(loc='lower center', ncol=2)\n",
    "\n",
    "ax1.plot(iters, training_losses, label='training loss')\n",
    "ax1.plot(iters, validation_losses, label='validation loss')\n",
    "ax1.set_ybound(0,5)\n",
    "ax1.set_ylabel('loss value')\n",
    "ax1.legend(loc='upper center', ncol=2)\n",
    "ax1.set_xlabel('# iterations (1 iter ~1.25 seconds for this GPU)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
